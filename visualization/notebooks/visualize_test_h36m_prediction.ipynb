{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use the following code to visualize your predictions before submission\n",
    "# You should have already validated the prediction format using validate_prediction_format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3710d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from util.dataset_util import read_video, read_cam_params, project_3d_to_2d, plot_over_image, read_data, show_image, load_data_from_pickle, load_data_from_picklev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17cf9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = '/Users/andreaongaro/Documents/Documenti Andrea Ongaro/Magistrale/Torino/Corsi/2_ANNO/ComputerVision/Project/lcn-pose/dataset/h36m_test.pkl'\n",
    "data_pred_path = '/Users/andreaongaro/Documents/Documenti Andrea Ongaro/Magistrale/Torino/Corsi/2_ANNO/ComputerVision/Project/lcn-pose/dataset/h36m_test.pkl'  # prediction file to be submitted; replace this with your prediction\n",
    "camera_name = '60457274' # select from ['50591643', '58860488', '60457274', '65906101']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d891a0",
   "metadata": {},
   "source": [
    "# Test Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1068a2430>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andreaongaro/.pyenv/versions/3.8.20/envs/py_cv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "  File \"/Users/andreaongaro/.pyenv/versions/3.8.20/envs/py_cv/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_trace_dispatch_regular.py\", line 354, in __call__\n",
      "    def __call__(self, frame, event, arg):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATI 3D\n",
      "[[ -293.70004272  -525.02728271  5461.41845703]\n",
      " [ -178.39385986  -543.30645752  5503.42773438]\n",
      " [ -159.13841248   -75.73199463  5566.43310547]\n",
      " [ -104.66836548   389.71435547  5567.62792969]\n",
      " [ -409.00668335  -506.74810791  5419.40771484]\n",
      " [ -435.45193481   -38.3963623   5473.39453125]\n",
      " [ -444.93322754   429.27697754  5445.10546875]\n",
      " [ -281.53082275  -774.20568848  5402.734375  ]\n",
      " [ -274.37295532 -1016.6463623   5340.68701172]\n",
      " [ -285.05099487 -1134.47021484  5363.85009766]\n",
      " [ -259.22705078 -1221.703125    5293.50878906]\n",
      " [ -430.40402222  -983.10876465  5250.54541016]\n",
      " [ -695.34552002  -900.02642822  5147.06054688]\n",
      " [ -943.16308594  -885.0067749   5127.84326172]\n",
      " [ -103.8538208  -1005.06622314  5406.90917969]\n",
      " [  159.92860413  -957.22424316  5533.14648438]\n",
      " [  354.78973389  -959.05328369  5688.17578125]]\n",
      "DATI 3D CONVERTITI\n",
      "[[  -54.36295989 -5005.56513339  5105.23714741]\n",
      " [ -164.59237052 -5045.38397104  5064.51417329]\n",
      " [   20.2298374  -5020.92767331  4630.68359767]\n",
      " [  169.77838914 -4934.685168    4195.01608752]\n",
      " [   55.86680373 -4965.74487592  5145.96058502]\n",
      " [  281.93184968 -4934.18592641  4732.60128249]\n",
      " [  488.98317809 -4821.23154597  4327.65736771]\n",
      " [ -174.15814454 -4993.0050999   5331.45197582]\n",
      " [ -286.68888677 -4976.11695099  5554.4546959 ]\n",
      " [ -326.38618441 -5020.86823641  5659.11823453]\n",
      " [ -389.8615627  -4966.66275517  5738.21942637]\n",
      " [ -135.1455851  -4887.9201902   5607.85817643]\n",
      " [  135.38168836 -4782.07593543  5666.31993194]\n",
      " [  364.86533533 -4770.74401666  5762.32661609]\n",
      " [ -433.0470392  -5031.96294205  5459.28764861]\n",
      " [ -645.6939511  -5136.25103936  5281.2113631 ]\n",
      " [ -816.09634313 -5280.76962348  5171.27641959]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATI 3D CONVERTITI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(j3d_in_camera)\n\u001b[0;32m---> 31\u001b[0m j2d_camera \u001b[38;5;241m=\u001b[39m \u001b[43mproject_3d_to_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj3d_in_camera\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstrinsics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw_distortion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATI 2D\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(j2d_camera)\n",
      "File \u001b[0;32m~/Documents/Documenti Andrea Ongaro/Magistrale/Torino/Corsi/2_ANNO/ComputerVision/Project/lcn-pose/visualization/notebooks/../util/dataset_util.py:62\u001b[0m, in \u001b[0;36mproject_3d_to_2d\u001b[0;34m(points3d, intrinsics, intrinsics_type)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mproject_3d_to_2d\u001b[39m(points3d, intrinsics, intrinsics_type):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Project 3D points to 2D using camera intrinsics.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        proj (numpy array): Projected 2D points.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mintrinsics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m#inverte\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     x \u001b[38;5;241m=\u001b[39m points3d[:, :\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m points3d[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     64\u001b[0m     r2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "frame_id = 0\n",
    "data = load_data_from_picklev2(data_test)\n",
    "j3d = data[frame_id][\"joint_3d_camera\"]\n",
    "\n",
    "T = data[frame_id][\"camera_param\"][\"T\"].reshape(1, 3)\n",
    "R = data[frame_id][\"camera_param\"][\"R\"]\n",
    "\n",
    "import json\n",
    "with open(\"/Users/andreaongaro/Documents/Documenti Andrea Ongaro/Magistrale/Torino/Corsi/2_ANNO/ComputerVision/Project/lcn-pose/dataset/human3.6/camera-parameters.json\", 'r') as f:\n",
    "    data_camera = json.load(f)\n",
    "instrinsics = {\n",
    "    \"f\": [[data_camera[\"intrinsics\"][camera_name][\"calibration_matrix\"][0][0],\n",
    "           data_camera[\"intrinsics\"][camera_name][\"calibration_matrix\"][0][1]]],\n",
    "    \"c\": [[data_camera[\"intrinsics\"][camera_name][\"calibration_matrix\"][0][2],\n",
    "           data_camera[\"intrinsics\"][camera_name][\"calibration_matrix\"][1][2]]],\n",
    "    \"k\": [[data_camera[\"intrinsics\"][camera_name][\"distortion\"][0],\n",
    "           data_camera[\"intrinsics\"][camera_name][\"distortion\"][1],\n",
    "           data_camera[\"intrinsics\"][camera_name][\"distortion\"][2],\n",
    "           ]],\n",
    "    \"p\": [[data_camera[\"intrinsics\"][camera_name][\"distortion\"][3],\n",
    "              data_camera[\"intrinsics\"][camera_name][\"distortion\"][4],\n",
    "              ]]\n",
    "\n",
    "}\n",
    "print(\"DATI 3D\")\n",
    "print(j3d)\n",
    "j3d_in_camera = np.matmul(np.array(j3d) - T, np.transpose(R))\n",
    "print(\"DATI 3D CONVERTITI\")\n",
    "print(j3d_in_camera)\n",
    "j2d_camera = project_3d_to_2d(j3d_in_camera, instrinsics, 'w_distortion')\n",
    "print(\"DATI 2D\")\n",
    "print(j2d_camera)\n",
    "plot_over_image([], j2d_camera, path_to_write=\"/Users/andreaongaro/Documents/Documenti Andrea Ongaro/Magistrale/Torino/Corsi/2_ANNO/ComputerVision/Project/lcn-pose/visualization/images/test_h36m.png\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j3ds = load_data_from_pickle(data_pred_path)\n",
    "frame_id = int(action_name) - 139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c47f9",
   "metadata": {},
   "source": [
    "# Predicted Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147363c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "frame_id = annotations[action_name]['fr_id']\n",
    "j3d = j3ds[frame_id]\n",
    "R = cam_params['extrinsics']['R']\n",
    "T = cam_params['extrinsics']['T']\n",
    "print(R.shape)\n",
    "print(T.shape)\n",
    "print(np.transpose(R).shape)\n",
    "# Convert 3D joint coordinates to camera coordinates\n",
    "# Note: The camera extrinsics are assumed to be in the format [R|T], where R is the rotation matrix and T is the translation vector.\n",
    "# The translation vector T is subtracted from the 3D joint coordinates before applying the rotation.\n",
    "# This is a common convention in computer vision, but you should verify that this is the case for your specific dataset.\n",
    "\n",
    "print(\"DATI 3D\")\n",
    "print(j3d)\n",
    "j3d_in_camera = np.matmul(np.array(j3d) - cam_params['extrinsics']['T'], np.transpose(cam_params['extrinsics']['R']))\n",
    "print(\"DATI 3D CONVERTITI\")\n",
    "print(j3d_in_camera)\n",
    "frame = frames[frame_id]\n",
    "j2d_camera = project_3d_to_2d(j3d_in_camera, cam_params['intrinsics_w_distortion'], 'w_distortion')\n",
    "print(\"DATI 2D\")\n",
    "print(j2d_camera)\n",
    "plot_over_image(frame, j2d_camera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
