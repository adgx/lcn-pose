    params['num_epochs'] = 200
    params['batch_size'] = 200
    # decay_strategy: lr * decay_rate ^ (epoch_num)
    params['decay_type'] = 'exp'  # 'step', 'exp'
    params['decay_params'] = {'decay_steps': 32000, 'decay_rate':0.96}  # param for exponential decay optimizer
    params['decay_params'].update({'boundaries': [250000, 500000, 1000000, 1350000], 'lr_values': [1e-3, 7e-4, 4e-4, 2e-4, 1e-4]})  # param for step optimizer
    params['eval_frequency'] = int(len(gt_dataset) / params['batch_size'])  # eval, summ & save after each epoch
    params['regularization'] = 0  # 5e-4, 0.0
    params['dropout'] = 0.25 if is_training else 0  # drop prob
    params['learning_rate'] = 1e-3


    #params['init_type'] = 'random'  # same, ones, random; only used when learnable

    params['num_layers'] = 3

    params['residual'] = True
    params['max_norm'] = True
    params['batch_norm'] = True

    


    """
    mask_type:
        locally_connected
        locally_connected_learn
    """
    params['mask_type'] = 'locally_connected'
    params['in_F'] = 2
    params['F'] = 64
    params['neighbour_matrix'] = get_neighbour_matrix_by_hand(filter_hub.neighbour_dict_set[0], knn=3)