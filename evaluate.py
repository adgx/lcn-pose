import pickle
import numpy as np
from tools import tools
import os
import prettytable
import argparse
import time

ROOT_PATH = os.path.dirname(os.path.realpath(__file__)) #returns the absolute path of the directory containing the script file

def parse_args():
    parser = argparse.ArgumentParser(description='evaluate')

    # general
    parser.add_argument('--data-type', help='scale', required=True, choices=['scale'], type=str)
    parser.add_argument('--mode', help='finetuned 2d detection or gt', required=True, choices=['gt', 'dt_ft'], type=str)
    #What is the difference between gt and dt_ft.
    #dt_ft->finetuned detection, gt=ground-truth


    # special
    parser.add_argument('--protocol2', help='whether use Procrustes', action='store_true')
    parser.add_argument('--test-indices', help='test idx list to eval', required=True, type=str)
    parser.add_argument('--per-joint',  help='joint-wise evaluation', action='store_true')
    parser.add_argument('--filename', type=str, default=None, help='Filename of the dataset', choices=["h36m", "humansc3d"])
    try :
        args = parser.parse_args()
    except:
        parser.print_help()
        raise SystemExit

    return args
#what are test indices?
#what is protocol2 and the Procrustes?
#So, the procrustes(MATLAB) distance quantifies the dissimilarity between two shapes by measuring how much one shape needs to be transformed to aling with
#another. This transformation includes translation, scaling, rotation, and reflection. The goal is to minimize the sum of squared differences between
#corresponding points of the shapes. 

#dataitem_gt is deserialized dataset
def _eval(test_name, dataitem_gt, commd, mode):
    #path  of the pkl file where are stored the outputs generated by model
    result_path = os.path.join(ROOT_PATH, 'experiment', test_name, 'result_%s.pkl' % mode) 


    with open(result_path, 'rb') as f:
        preds = pickle.load(f)['result']  # [N, 17, 3] this oject is a dictionary with a key 'result' that has a values of pose for one video (?)
    preds = np.reshape(preds, (-1, 17, 3)) #make the python vector a np vector

    assert len(preds) == len(dataitem_gt) #so the lenght of preds must be equal to dataitem_gt

    results = [] #what is it for?
    for idx, pred in enumerate(preds): #enumetate adds a counter for each iterable item
        pred = tools.image_to_camera_frame(pose3d_image_frame=pred, box=dataitem_gt[idx]['box'],
            camera=dataitem_gt[idx]['camera_param'], rootIdx=0,
            root_depth=dataitem_gt[idx]['root_depth'])#adjust the 3d pose predict evaluating the intrisic camera's parameters 
        gt = dataitem_gt[idx]['joint_3d_camera']
        if 'protocol2' in commd:
            pred = tools.align_to_gt(pose=pred, pose_gt=gt)
        error_per_joint = np.sqrt(np.square(pred-gt).sum(axis=1))  # [17] for each row of the squared error sum the columns vaules
        results.append(error_per_joint)
        if idx % 10000 == 0:
            print('step:%d' % idx + '-' * 20)
            print(np.mean(error_per_joint))
    #calculate pck
    results = np.array(results)  # [N ,17] error per joint for each frame

    #the gendbRe not define a key 'action' for the dataset's dataitem 
    if 'action' in commd:
        final_result = []
        action_index_dict = {}
        for i in range(2, 17):
            action_index_dict[i] = []
        for idx, dataitem in enumerate(dataitem_gt):
            action_index_dict[dataitem['action']].append(idx)
        for i in range(2, 17):
            final_result.append(np.mean(results[action_index_dict[i]])) #no PCK
        error = np.mean(np.array(final_result))
        final_result.append(error)
    elif 'joint' in commd:
        error = np.mean(results, axis=0)  # [17] mean error for each joint evalutes all frames
        final_result = error.tolist() + [np.mean(error)] # concatenate the mean error of all joints to the error list
    else:
        assert 0, 'not implemented commd'
    
    return final_result

#pkl is the dataset 
def eval(commd, test_indices, mode='dt', pkl=""):
    err_dict = {} #what is it for?

    print('loading dataset')

    DATAITEM_GT_PATH = os.path.join(ROOT_PATH, pkl) #search the plk file from the script's dir
    with open(DATAITEM_GT_PATH, 'rb') as f:
        dataitem_gt = pickle.load(f)

    # eval each trial
    for i in test_indices:
        test_name = 'test%d' % i
        err_dict[test_name] = _eval(test_name, dataitem_gt, commd, mode)

        # log each trial respectively
        table = prettytable.PrettyTable()
        if 'action' in commd:
            table.field_names = ['test_name'] + [i for i in range(2, 17)] + ['avg']
        elif 'joint' in commd:
            table.field_names = ['test_name'] + [i for i in range(0, 17)] + ['avg']
        else:
            assert 0, 'not implemented commd'
        table.add_row([test_name] + ['%.2f' % d for d in err_dict[test_name]])

        time_str = time.strftime('%Y-%m-%d-%H-%M')
        #make a file where store the error evaluation results 
        log_path = os.path.join(ROOT_PATH, 'experiment', test_name, 'err_{}_{}_{}.log'.format(commd, mode, time_str))

        f = open(log_path, 'w')
        print(table, file=f)
        f.close()

    # print summary table to the screen
    summary_table = prettytable.PrettyTable()
    if 'action' in commd:
        summary_table.field_names = ['test_name'] + [i for i in range(2, 17)] + ['avg']
    elif 'joint' in commd:
        summary_table.field_names = ['test_name'] + [i for i in range(0, 17)] + ['avg']
    else:
        assert 0, 'not implemented commd'

    for k, v in err_dict.items():
        summary_table.add_row([k] + ['%.2f' % d for d in v])
    print(summary_table)


if __name__ == '__main__':

    args = parse_args()
    test_indices = sorted([int(i) for i in args.test_indices.split(',')]) #sort the passed indices 
    commd = args.data_type #always scale
    if args.per_joint: #per_joint can have the true or false value
        commd += '_joint'
    else:
        commd += '_action' #evaluating per azione
    if args.protocol2: #protocol2 can have the true or false value
        commd += '_protocol2'

    print('=> commd:', commd)
    print('=> mode:', args.mode) #mode can be gt or dt_ft
    print('=> eval experiments:', test_indices)
    #eval recieve a pkl file!
    eval(commd=commd, test_indices=test_indices, mode=args.mode, pkl=args.filename)

